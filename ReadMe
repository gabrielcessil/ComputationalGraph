# **Project Overview**

### In modern numerical computing and machine learning, automatic differentiation (AutoDiff) plays a crucial role in efficiently computing gradients for optimization problems. This project implements a computational graph-based automatic differentiation system, where mathematical expressions are represented as directed graphs. Each node in the graph corresponds to an operation (e.g., addition, multiplication, sine, power), while edges capture dependencies between variables.

# **Project Features**

## This project provides:

### - A class-based implementation of a computational graph, allowing users to construct expressions dynamically.
### - Support for common mathematical operations (addition, multiplication, exponentiation, trigonometric functions).
### - Graph-based differentiation, enabling efficient computation of gradients via backpropagation.
### - A structured visualization of the computational graph, helping users understand function composition.



## **Unfornutelly, the current state of the code still do not support matrices.**
## **Feel free to add examples and use it as a didactic source**
